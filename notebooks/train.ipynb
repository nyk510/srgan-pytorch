{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srgan.model import Generator, Discriminator\n",
    "from srgan.dataset import DatasetFromQuery\n",
    "from srgan.utils import get_logger\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetFromQuery(query='/workdir/dataset/BSDS300/images/train/*.jpg', shrink_scale=4, max_size=96, input_upsample=False)\n",
    "loader = DataLoader(dataset, batch_size=64, num_workers=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.vgg import vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGLoss(nn.Module):\n",
    "    def __init__(self, layer='22', device=None):\n",
    "        super().__init__()\n",
    "        vgg = vgg19(pretrained=True)\n",
    "        \n",
    "        if layer == '22':\n",
    "            self.vgg_feature = vgg.features[:11]\n",
    "            \n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.mean = torch.tensor(self.mean, device=device)[None, :, None, None]\n",
    "        self.std = [0.229, 0.224, 0.225]\n",
    "        self.std = torch.tensor(self.std, device=device)[None, :, None, None]            \n",
    "        self.loss = nn.MSELoss()\n",
    "        \n",
    "    def normalize(self, tensor):\n",
    "        tensor = tensor.clone()\n",
    "        tensor.sub_(self.mean).div_(self.std)\n",
    "        return tensor\n",
    "        \n",
    "    def forward(self, img_high, img_fake):\n",
    "        z_high = self.vgg_feature(self.normalize(img_high))\n",
    "        z_low = self.vgg_feature(self.normalize(img_fake))\n",
    "        return self.loss(z_high, z_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "pretrained model の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator()\n",
    "dis = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = '/workdir/dataset/gen_pretrain.hdf5'\n",
    "gen.load_state_dict(torch.load(pretrained_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_criterion = nn.BCELoss()\n",
    "vgg_criterion = VGGLoss(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGGLoss(\n",
       "  (vgg_feature): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (loss): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen, dis = gen.to(DEVICE), dis.to(DEVICE)\n",
    "vgg_criterion.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_gen = Adam(params=gen.parameters(), lr=1e-4)\n",
    "opt_dis = Adam(params=dis.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-01-12 20:17:23,514] start epoch: 1\n",
      "[2020-01-12 20:18:33,986] 199/1563\tdis_loss 8.2639e-04\tgen_loss 1.3214e+01\tcontent_loss 1.2864e+01\tadv_loss 3.5032e+01\n",
      "[2020-01-12 20:19:44,436] 399/1563\tdis_loss 2.6447e-05\tgen_loss 1.3270e+01\tcontent_loss 1.2905e+01\tadv_loss 3.6420e+01\n",
      "[2020-01-12 20:20:54,766] 599/1563\tdis_loss 1.0314e-08\tgen_loss 1.3306e+01\tcontent_loss 1.2915e+01\tadv_loss 3.9072e+01\n",
      "[2020-01-12 20:22:05,101] 799/1563\tdis_loss 1.0696e-08\tgen_loss 1.3171e+01\tcontent_loss 1.2788e+01\tadv_loss 3.8318e+01\n",
      "[2020-01-12 20:23:15,889] 999/1563\tdis_loss 1.1344e-07\tgen_loss 1.3102e+01\tcontent_loss 1.2742e+01\tadv_loss 3.5996e+01\n",
      "[2020-01-12 20:24:27,389] 1199/1563\tdis_loss 8.7718e-05\tgen_loss 1.3112e+01\tcontent_loss 1.2729e+01\tadv_loss 3.8297e+01\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    logger.info(f'start epoch: {epoch}')\n",
    "    watch_logs = defaultdict(list)\n",
    "    log_df = pd.DataFrame()\n",
    "    for i, (img_low, img_high) in enumerate(loader):\n",
    "        img_low, img_high = img_low.to(DEVICE), img_high.to(DEVICE)\n",
    "        img_fake = gen(img_low)\n",
    "\n",
    "        # step1: update discriminator\n",
    "        pred_high = dis(img_high)\n",
    "        pred_fake = dis(img_fake.detach())\n",
    "        dis_loss = bce_criterion(pred_high, torch.full_like(pred_high, 1, device=DEVICE)) + bce_criterion(pred_fake, torch.full_like(pred_fake, 0))\n",
    "        opt_dis.zero_grad()\n",
    "        dis_loss.backward()\n",
    "        opt_dis.step()\n",
    "\n",
    "        # step2: generator の update\n",
    "        pred_fake = dis(img_fake)\n",
    "        content_loss = vgg_criterion(img_fake, img_high)\n",
    "        adv_loss = bce_criterion(pred_fake, torch.full_like(pred_fake, 1, device=DEVICE))\n",
    "        gen_loss = content_loss + 1e-2 * adv_loss\n",
    "        opt_gen.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        update_data = {\n",
    "            'dis_loss': dis_loss.item(),\n",
    "            'gen_loss': gen_loss.item(),\n",
    "            'content_loss': content_loss.item(),\n",
    "            'adv_loss': adv_loss.item()\n",
    "        }\n",
    "\n",
    "        for k, v in update_data.items():\n",
    "            watch_logs[k].append(v)\n",
    "\n",
    "        if (i + 1) % 200 == 0:\n",
    "            s = pd.DataFrame(watch_logs).mean()\n",
    "            str_log = [f'{i}/{len(loader)}']\n",
    "            for k, v in s.items():\n",
    "                str_log.append(f'{k} {v:.4e}')\n",
    "            logger.info('\\t'.join(str_log))\n",
    "            s['n_steps'] = i\n",
    "            s['epoch'] = epoch\n",
    "            log_df = log_df.append(s, ignore_index=True)\n",
    "            watch_logs = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(), '/workdir/dataset/generator.hdf5')\n",
    "torch.save(dis.state_dict(), '/workdir/dataset/discriminator.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
